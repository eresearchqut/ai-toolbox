"use strict";(self.webpackChunkai_toolbox=self.webpackChunkai_toolbox||[]).push([[339],{"./src/components/tool/HuggingFacePipeline/Instructions/Instructions.stories.js":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{__webpack_require__.r(__webpack_exports__),__webpack_require__.d(__webpack_exports__,{LyraGPU:()=>LyraGPU,__namedExportsOrder:()=>__namedExportsOrder,default:()=>__WEBPACK_DEFAULT_EXPORT__});const __WEBPACK_DEFAULT_EXPORT__={title:"Tools/HuggingFacePipeline/Instructions",component:__webpack_require__("./src/components/tool/HuggingFacePipeline/Instructions/Instructions.js").t},LyraGPU={args:{task:"text-generation",model:"bigscience/bloom",config:{service:"Lyra",hardware:"GPU",cpuVendor:"Any",cpuCores:8,ram:32,gpuVendor:"NVIDIA",gpuModel:"A100",gpuModules:8,tool:"CLI",environment:"Singularity"},port:3456},argTypes:{config:{tool:{control:{type:"select",options:["CLI","API"]}}}}};LyraGPU.parameters={...LyraGPU.parameters,docs:{...LyraGPU.parameters?.docs,source:{originalSource:'{\n  args: {\n    task: \'text-generation\',\n    model: \'bigscience/bloom\',\n    config: {\n      service: "Lyra",\n      hardware: "GPU",\n      cpuVendor: "Any",\n      cpuCores: 8,\n      ram: 32,\n      gpuVendor: "NVIDIA",\n      gpuModel: "A100",\n      gpuModules: 8,\n      tool: "CLI",\n      environment: "Singularity"\n    },\n    port: 3456\n  },\n  argTypes: {\n    config: {\n      tool: {\n        control: {\n          type: \'select\',\n          options: [\'CLI\', \'API\']\n        }\n      }\n    }\n  }\n}',...LyraGPU.parameters?.docs?.source}}};const __namedExportsOrder=["LyraGPU"]}}]);